---
title: GitHub Models integration
description: Learn how to integrate Aspire with GitHub Models for AI model access and management.
prev: false
---

import InstallPackage from '@components/InstallPackage.astro';
import InstallDotNetPackage from '@components/InstallDotNetPackage.astro';
import { Aside } from '@astrojs/starlight/components';
import ThemeImage from '@components/ThemeImage.astro';
import githubIcon from '@assets/icons/github-icon.png';
import githubLightIcon from '@assets/icons/github-light-icon.png';

<ThemeImage
  light={githubLightIcon}
  dark={githubIcon}
  alt="GitHub logo"
  width={80}
  height={80}
  zoomable={false}
  classOverride="float-inline-left icon"
/>

[GitHub Models](https://docs.github.com/github-models) provides access to various AI models including OpenAI's GPT models, DeepSeek, Microsoft's Phi models, and other leading AI models, all accessible through GitHub's infrastructure. The Aspire GitHub Models integration enables you to connect to GitHub Models from your applications for prototyping and production scenarios.

## Hosting integration

The Aspire GitHub Models hosting integration models GitHub Models resources as `GitHubModelResource`. To access these types and APIs, install the [ðŸ“¦ Aspire.Hosting.GitHub.Models](https://www.nuget.org/packages/Aspire.Hosting.GitHub.Models) NuGet package:

<InstallPackage packageName="Aspire.Hosting.GitHub.Models" />

### Add a GitHub Model resource

To add a `GitHubModelResource` to your AppHost project, call the `AddGitHubModel` method:

```csharp title="C# â€” AppHost.cs"
var builder = DistributedApplication.CreateBuilder(args);

var model = GitHubModel.OpenAI.OpenAIGpt4oMini;
var chat = builder.AddGitHubModel("chat", model);

builder.AddProject<Projects.ExampleProject>()
       .WithReference(chat);

builder.Build().Run();
```

The preceding code adds a GitHub Model resource named `chat` using the `GitHubModel` constant for OpenAI's GPT-4o-mini model. The `WithReference` method passes the connection information to the `ExampleProject` project.

<Aside type="tip">
  Use the strongly-typed `GitHubModel` constants to avoid typos and ensure
  you're using valid model identifiers. These constants are grouped by publisher
  (for example, `GitHubModel.OpenAI.OpenAIGpt4oMini`,
  `GitHubModel.Microsoft.Phi4MiniInstruct`,
  `GitHubModel.DeepSeek.DeepSeekV30324`).
</Aside>

### Specify an organization

For organization-specific requests, you can specify an organization parameter:

```csharp title="C# â€” AppHost.cs"
var builder = DistributedApplication.CreateBuilder(args);

var organization = builder.AddParameter("github-org");
var model = GitHubModel.OpenAI.OpenAIGpt4oMini;
var chat = builder.AddGitHubModel("chat", model, organization);

builder.AddProject<Projects.ExampleProject>()
       .WithReference(chat);

builder.Build().Run();
```

When an organization is specified, the token must be attributed to that organization in GitHub.

### Configure API key authentication

The GitHub Models integration supports multiple ways to configure authentication:

#### Default API key parameter

By default, the integration creates a parameter named `{resource_name}-gh-apikey` that automatically falls back to the `GITHUB_TOKEN` environment variable:

```csharp
var model = GitHubModel.OpenAI.OpenAIGpt4oMini;
var chat = builder.AddGitHubModel("chat", model);
```

Then in user secrets:

```json
{
  "Parameters": {
    "chat-gh-apikey": "YOUR_GITHUB_TOKEN_HERE"
  }
}
```

#### Custom API key parameter

You can also specify a custom parameter for the API key:

```csharp
var apiKey = builder.AddParameter("my-api-key", secret: true);
var model = GitHubModel.OpenAI.OpenAIGpt4oMini;
var chat = builder.AddGitHubModel("chat", model)
                  .WithApiKey(apiKey);
```

Then in user secrets:

```json
{
  "Parameters": {
    "my-api-key": "YOUR_GITHUB_TOKEN_HERE"
  }
}
```

### Health checks

You can add health checks to verify the GitHub Models endpoint accessibility and API key validity:

```csharp
var model = GitHubModel.OpenAI.OpenAIGpt4oMini;
var chat = builder.AddGitHubModel("chat", model)
                  .WithHealthCheck();
```

<Aside type="caution">
  Because health checks are included in the rate limit of the GitHub Models API,
  use this health check sparingly, such as when debugging connectivity issues.
  The health check runs only once per application instance to minimize API
  usage.
</Aside>

### Available models

GitHub Models supports various AI models. Use the strongly-typed `GitHubModel` constants for the most up-to-date list of available models. Some popular options include:

- `GitHubModel.OpenAI.OpenAIGpt4oMini`
- `GitHubModel.OpenAI.OpenAIGpt41Mini`
- `GitHubModel.DeepSeek.DeepSeekV30324`
- `GitHubModel.Microsoft.Phi4MiniInstruct`

Check the [GitHub Models documentation](https://docs.github.com/github-models) for more information about these models and their capabilities.

### Connection properties

When you reference a GitHub Model resource using `WithReference`, the following connection properties are made available to the consuming project:

#### GitHub Model

The GitHub Model resource exposes the following connection properties:

| Property Name  | Description                                                                                    |
| -------------- | ---------------------------------------------------------------------------------------------- |
| `Uri`          | The GitHub Models inference endpoint URI, with the format `https://models.github.ai/inference` |
| `Key`          | The API key (PAT or GitHub App token) for authentication                                       |
| `Model`        | The model identifier for inference requests, for instance `openai/gpt-4o-mini`                 |
| `Organization` | The organization attributed to the request (available when configured)                         |

**Example properties:**

```
Uri: https://models.github.ai/inference
Model: openai/gpt-4o-mini
```

<Aside type="note">
  Aspire exposes each property as an environment variable named
  `[RESOURCE]_[PROPERTY]`. For instance, the `Uri` property of a resource called
  `chat` becomes `CHAT_URI`.
</Aside>

## Client integration

To get started with the Aspire GitHub Models client integration, you can use either the Azure AI Inference client or the OpenAI client, depending on your needs and model compatibility.

### Using Azure AI Inference client

Install the [ðŸ“¦ Aspire.Azure.AI.Inference](https://www.nuget.org/packages/Aspire.Azure.AI.Inference) NuGet package in the client-consuming project:

<InstallDotNetPackage packageName="Aspire.Azure.AI.Inference" />

#### Add a ChatCompletionsClient

In the `Program.cs` file of your client-consuming project, use the `AddAzureChatCompletionsClient` method to register a `ChatCompletionsClient` for dependency injection:

```csharp
builder.AddAzureChatCompletionsClient("chat");
```

You can then retrieve the `ChatCompletionsClient` instance using dependency injection:

```csharp
public class ExampleService(ChatCompletionsClient client)
{
    public async Task<string> GetResponseAsync(string prompt)
    {
        var response = await client.GetChatCompletionsAsync(
            new[]
            {
                new ChatMessage(ChatRole.User, prompt)
            });

        return response.Value.Choices[0].Message.Content;
    }
}
```

#### Add ChatCompletionsClient with registered IChatClient

If you're using the Microsoft.Extensions.AI abstractions, you can register an `IChatClient`:

```csharp
builder.AddAzureChatCompletionsClient("chat")
       .AddChatClient();
```

Then use it in your services:

```csharp
public class StoryService(IChatClient chatClient)
{
    public async Task<string> GenerateStoryAsync(string prompt)
    {
        var response = await chatClient.GetResponseAsync(prompt);

        return response.Text;
    }
}
```

### Using OpenAI client

For models compatible with the OpenAI API (such as `openai/gpt-4o-mini`), you can use the OpenAI client. Install the [ðŸ“¦ Aspire.OpenAI](https://www.nuget.org/packages/Aspire.OpenAI) NuGet package:

<InstallDotNetPackage packageName="Aspire.OpenAI" />

#### Add an OpenAI client

```csharp
builder.AddOpenAIClient("chat");
```

You can then use the OpenAI client:

```csharp
public class ChatService(OpenAIClient client)
{
    public async Task<string> GetChatResponseAsync(string prompt)
    {
        var chatClient = client.GetChatClient(GitHubModel.OpenAI.OpenAIGpt4oMini);
        var response = await chatClient.CompleteChatAsync(
            new[]
            {
                new UserChatMessage(prompt)
            });

        return response.Value.Content[0].Text;
    }
}
```

#### Add OpenAI client with registered IChatClient

```csharp
builder.AddOpenAIClient("chat")
       .AddChatClient();
```

### Configuration

The GitHub Models integration supports configuration through user secrets, environment variables, or app settings. The integration automatically uses the `GITHUB_TOKEN` environment variable if available, or you can specify a custom API key parameter.

#### Authentication

The GitHub Models integration requires a GitHub personal access token with `models: read` permission. The token can be provided in several ways:

##### Environment variables in Codespaces and GitHub Actions

When running an app in GitHub Codespaces or GitHub Actions, the `GITHUB_TOKEN` environment variable is automatically available and can be used without additional configuration. This token has the necessary permissions to access GitHub Models for the repository context.

```csharp
// No additional configuration needed in Codespaces/GitHub Actions
var model = GitHubModel.OpenAI.OpenAIGpt4oMini;
var chat = builder.AddGitHubModel("chat", model);
```

##### Personal access tokens for local development

For local development, you need to create a [fine-grained personal access token](https://github.com/settings/tokens) with the `models: read` scope and configure it in user secrets:

```json
{
  "Parameters": {
    "chat-gh-apikey": "github_pat_YOUR_TOKEN_HERE"
  }
}
```

#### Connection string format

The connection string follows this format:

```plaintext
Endpoint=https://models.github.ai/inference;Key={api_key};Model={model_name};DeploymentId={model_name}
```

For organization-specific requests:

```plaintext
Endpoint=https://models.github.ai/orgs/{organization}/inference;Key={api_key};Model={model_name};DeploymentId={model_name}
```

### Rate limits and costs

<Aside type="caution">
  Each model has rate limits that vary by model and usage tier. Some models
  include costs if you exceed free tier limits. Check the [GitHub Models
  documentation](https://docs.github.com/github-models) for current rate limits
  and pricing information.
</Aside>

<Aside type="tip">
  Use health checks sparingly to avoid consuming your rate limit allowance. The
  integration caches health check results to minimize API calls.
</Aside>

### Sample application

The `dotnet/aspire` repo contains an example application demonstrating the GitHub Models integration. You can find the sample in the [Aspire GitHub repository](https://github.com/dotnet/aspire/tree/main/playground/GitHubModelsEndToEnd).

## Observability and telemetry

### Logging

The GitHub Models integration uses standard HTTP client logging categories:

- `System.Net.Http.HttpClient`
- `Microsoft.Extensions.Http`

### Tracing

HTTP requests to the GitHub Models API are automatically traced when using the Azure AI Inference or OpenAI clients.

## See also

- [GitHub Models](https://docs.github.com/github-models)
- [Aspire GitHub repo](https://github.com/dotnet/aspire)
- [GitHub Models API documentation](https://docs.github.com/rest/models/inference)
